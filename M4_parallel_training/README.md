# Parallel Training with FSDP (PyTorch 2.5)  

Trains **GPT-2** on **OpenWebText** using **PyTorch Fully Sharded Data Parallel (FSDP)**.  

## Objective  
Leverage **FSDP** for efficient multi-GPU training on Kaggle's double GPU instance.  

## Constraints  
- Use PyTorch 2.5
- No Hugging Face Transformers or Accelerate