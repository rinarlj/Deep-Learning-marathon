# Preference Tuning with PPO  

This project **detoxifies** the **EleutherAI/pythia-410m-deduped** model using **Proximal Policy Optimization (PPO)** to improve language model safety and reduce harmful outputs.  

(Guide for starting point can be found at [Detoxifying a Language Model](https://huggingface.co/docs/trl/detoxifying_a_lm).)  